{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Data Creation and SQL insertion\n",
    "\n",
    "The data generator produces a rich synthetic dataset with many-to-many relationships such as product-location pairs. \n",
    "The demo code requires you to have an environment (supplychain) that has pyodbc, urllib, sqlalchemy and azureml-defaults.\n",
    "This Notebook performs the following actions:\n",
    "1) Pre-Populates the Azure SQL Database sales and sales training tables with our synthetic data.\n",
    "2) Pre-populates the Azure SQL Database parameters table for running inventory optimization simulations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/supplychain/lib/python3.8/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "import sys\n",
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "from sqlalchemy import create_engine,text, insert, update,Table\n",
    "\n",
    "from azureml.core import Workspace, Datastore, Dataset, Experiment\n",
    "from azureml.data.datapath import DataPath\n",
    " \n",
    " \n",
    "\n",
    "from gluonts.dataset.common import load_datasets, ListDataset\n",
    "from gluonts.dataset.field_names import FieldName\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.mx import DeepAREstimator\n",
    "from gluonts.mx.distribution.gaussian import GaussianOutput\n",
    "from gluonts.mx.trainer import Trainer\n",
    "from gluonts.model.predictor import Predictor\n",
    "\n",
    "\n",
    "from azure.ai.ml import command, Input, Output\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "workspace = Workspace.from_config()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Populate the Azure SQL Database sales and sales training tables with our synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class SalesDataModel(Enum):\n",
    "    RANDOM = 0\n",
    "    SINUSOID = 1\n",
    "    SPARSE = 2\n",
    "\n",
    "from typing import List, Mapping\n",
    "\n",
    "class SalesDataGenerator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        start_date: datetime,\n",
    "        num_days: int,\n",
    "        item_to_location: Mapping[str, List[str]],\n",
    "        item_to_class: Mapping[str, List[str]],\n",
    "        min_sales_per_day: int = 0,\n",
    "        max_sales_per_day: int = 1000,\n",
    "    ):\n",
    "        self.start_date = start_date\n",
    "        self.num_days = num_days\n",
    "        self.item_to_location = item_to_location\n",
    "        self.item_to_class = item_to_class\n",
    "        self.min_sales_per_day = min_sales_per_day\n",
    "        self.max_sales_per_day = max_sales_per_day\n",
    "\n",
    "    def synthesize(self, data_model: SalesDataModel = SalesDataModel.RANDOM):\n",
    "        sales_df = pd.DataFrame(columns=[\"Date\", \"Item\", \"Location\", \"Sales\"])\n",
    "        for item, locations in self.item_to_location.items():\n",
    "            for location in locations:\n",
    "                if data_model == SalesDataModel.RANDOM:\n",
    "                    sales = np.random.randint(\n",
    "                        self.min_sales_per_day, self.max_sales_per_day, self.num_days\n",
    "                    )\n",
    "                elif data_model == SalesDataModel.SINUSOID:\n",
    "                    alpha = 0.9\n",
    "                    gain = alpha * (self.max_sales_per_day - self.min_sales_per_day)\n",
    "                    periods = np.random.randint(1, 6, 1)\n",
    "                    nn = np.linspace(0, int(periods), self.num_days)\n",
    "                    base_sales = (\n",
    "                        gain * np.abs(np.cos(np.pi * nn))\n",
    "                        + alpha * self.min_sales_per_day\n",
    "                    )\n",
    "                    noise = np.random.randint(\n",
    "                        (1 - alpha) * self.min_sales_per_day,\n",
    "                        (1 - alpha) * self.max_sales_per_day,\n",
    "                        self.num_days,\n",
    "                    )\n",
    "                    sales = base_sales + noise\n",
    "                    sales = sales.astype(int).tolist()\n",
    "                elif data_model == SalesDataModel.SPARSE:\n",
    "                    thresh = 0.1\n",
    "                    sales = [\n",
    "                        0\n",
    "                        if np.random.rand() > thresh\n",
    "                        else np.random.randint(\n",
    "                            self.min_sales_per_day, self.max_sales_per_day, 1\n",
    "                        )\n",
    "                        for _ in range(self.num_days)\n",
    "                    ]\n",
    "                _sales_df = pd.DataFrame(\n",
    "                    {\n",
    "                        \"Date\": [\n",
    "                            self.start_date + timedelta(days=diff)\n",
    "                            for diff in range(self.num_days)\n",
    "                        ],\n",
    "                        \"Item\": [item] * self.num_days,\n",
    "                        \"Location\": [location] * self.num_days,\n",
    "                        \"Sales\": sales,\n",
    "                        \"Item_Class\": [self.item_to_class[item]] * self.num_days,\n",
    "                    }\n",
    "                )\n",
    "                sales_df = pd.concat([sales_df, _sales_df], ignore_index=True)\n",
    "        \n",
    "        # hnd, ord, bkd generation\n",
    "        items = list(self.item_to_location.keys())\n",
    "        qtyoh, cost, tons, unit_cost = [], [], [], []\n",
    "        for item in items: \n",
    "            # QTYOH Randomly selected beween min_sales and max_sales\n",
    "            _qtyoh = random.randint(\n",
    "                min(0, self.min_sales_per_day), \n",
    "                self.max_sales_per_day\n",
    "            )\n",
    "            qtyoh.append(_qtyoh)\n",
    "            # Tons is randomly chosen between 1 and 10 tons\n",
    "            tons.append(\n",
    "                _qtyoh * max(1.0, 10 * random.random())\n",
    "            )\n",
    "            # Cost is randomly selected bewteen 1 and 100\n",
    "            _cost = round(max(1.0, 100 * random.random()), 2)\n",
    "            cost.append(_cost)\n",
    "            unit_cost.append(_cost / _qtyoh)\n",
    "\n",
    "        hnd_df = pd.DataFrame(\n",
    "            {\n",
    "                \"Item\": items,\n",
    "                \"QTYOH\": qtyoh,\n",
    "                \"Cost\": cost, \n",
    "                \"Tons\": tons,\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # percentage randomly selected representing the percent of qtyoh that will be ordered\n",
    "        coeff = round(random.random(), 2)\n",
    "        # Each arrival is randomly selected over the sales generation window \n",
    "        arrival_dates = [\n",
    "            self.start_date + timedelta(days=random.randint(0, self.num_days))\n",
    "            for _ in range(len(items))\n",
    "        ]\n",
    "        ord_df = pd.DataFrame(\n",
    "            {\n",
    "                \"Item\": items, \n",
    "                \"Total_Cost\": [coeff * c for c in cost],\n",
    "                \"Tons\": [coeff * t for t in tons],\n",
    "                \"Quantity\": [coeff * q for q in qtyoh], \n",
    "                \"Arrival_Date\": arrival_dates,\n",
    "            }\n",
    "        )\n",
    "        # shipping is chosen to be randomly between 2 and 5 days\n",
    "        bkd_df = pd.DataFrame(\n",
    "            {\n",
    "                \"Item\": items, \n",
    "                \"Ship_Date\": [sd + timedelta(days=random.choice([2,3,4,5])) for sd in arrival_dates],\n",
    "                \"Qty_Remain\": [(1-coeff) * q for q in qtyoh],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return sales_df, hnd_df, ord_df, bkd_df\n",
    "    \n",
    "from typing import List, Mapping\n",
    "\n",
    "class SalesDataGenerator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        start_date: datetime,\n",
    "        num_days: int,\n",
    "        item_to_location: Mapping[str, List[str]],\n",
    "        item_to_class: Mapping[str, List[str]],\n",
    "        min_sales_per_day: int = 0,\n",
    "        max_sales_per_day: int = 1000,\n",
    "    ):\n",
    "        self.start_date = start_date\n",
    "        self.num_days = num_days\n",
    "        self.item_to_location = item_to_location\n",
    "        self.item_to_class = item_to_class\n",
    "        self.min_sales_per_day = min_sales_per_day\n",
    "        self.max_sales_per_day = max_sales_per_day\n",
    "\n",
    "    def synthesize(self, data_model: SalesDataModel = SalesDataModel.RANDOM):\n",
    "        sales_df = pd.DataFrame(columns=[\"Date\", \"Item\", \"Location\", \"Sales\"])\n",
    "        for item, locations in self.item_to_location.items():\n",
    "            for location in locations:\n",
    "                if data_model == SalesDataModel.RANDOM:\n",
    "                    sales = np.random.randint(\n",
    "                        self.min_sales_per_day, self.max_sales_per_day, self.num_days\n",
    "                    )\n",
    "                elif data_model == SalesDataModel.SINUSOID:\n",
    "                    alpha = 0.9\n",
    "                    gain = alpha * (self.max_sales_per_day - self.min_sales_per_day)\n",
    "                    periods = np.random.randint(1, 6, 1)\n",
    "                    nn = np.linspace(0, int(periods), self.num_days)\n",
    "                    base_sales = (\n",
    "                        gain * np.abs(np.cos(np.pi * nn))\n",
    "                        + alpha * self.min_sales_per_day\n",
    "                    )\n",
    "                    noise = np.random.randint(\n",
    "                        (1 - alpha) * self.min_sales_per_day,\n",
    "                        (1 - alpha) * self.max_sales_per_day,\n",
    "                        self.num_days,\n",
    "                    )\n",
    "                    sales = base_sales + noise\n",
    "                    sales = sales.astype(int).tolist()\n",
    "                elif data_model == SalesDataModel.SPARSE:\n",
    "                    thresh = 0.1\n",
    "                    sales = [\n",
    "                        0\n",
    "                        if np.random.rand() > thresh\n",
    "                        else np.random.randint(\n",
    "                            self.min_sales_per_day, self.max_sales_per_day, 1\n",
    "                        )\n",
    "                        for _ in range(self.num_days)\n",
    "                    ]\n",
    "                _sales_df = pd.DataFrame(\n",
    "                    {\n",
    "                        \"Date\": [\n",
    "                            self.start_date + timedelta(days=diff)\n",
    "                            for diff in range(self.num_days)\n",
    "                        ],\n",
    "                        \"Item\": [item] * self.num_days,\n",
    "                        \"Location\": [location] * self.num_days,\n",
    "                        \"Sales\": sales,\n",
    "                        \"Item_Class\": [self.item_to_class[item]] * self.num_days,\n",
    "                    }\n",
    "                )\n",
    "                sales_df = pd.concat([sales_df, _sales_df], ignore_index=True)\n",
    "        \n",
    "        # hnd, ord, bkd generation\n",
    "        items = list(self.item_to_location.keys())\n",
    "        qtyoh, cost, tons, unit_cost = [], [], [], []\n",
    "        for item in items: \n",
    "            # QTYOH Randomly selected beween min_sales and max_sales\n",
    "            _qtyoh = random.randint(\n",
    "                min(0, self.min_sales_per_day), \n",
    "                self.max_sales_per_day\n",
    "            )\n",
    "            qtyoh.append(_qtyoh)\n",
    "            # Tons is randomly chosen between 1 and 10 tons\n",
    "            tons.append(\n",
    "                _qtyoh * max(1.0, 10 * random.random())\n",
    "            )\n",
    "            # Cost is randomly selected bewteen 1 and 100\n",
    "            _cost = round(max(1.0, 100 * random.random()), 2)\n",
    "            cost.append(_cost)\n",
    "            unit_cost.append(_cost / _qtyoh)\n",
    "\n",
    "        hnd_df = pd.DataFrame(\n",
    "            {\n",
    "                \"Item\": items,\n",
    "                \"QTYOH\": qtyoh,\n",
    "                \"Cost\": cost, \n",
    "                \"Tons\": tons,\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # percentage randomly selected representing the percent of qtyoh that will be ordered\n",
    "        coeff = round(random.random(), 2)\n",
    "        # Each arrival is randomly selected over the sales generation window \n",
    "        arrival_dates = [\n",
    "            self.start_date + timedelta(days=random.randint(0, self.num_days))\n",
    "            for _ in range(len(items))\n",
    "        ]\n",
    "        ord_df = pd.DataFrame(\n",
    "            {\n",
    "                \"Item\": items, \n",
    "                \"Total_Cost\": [coeff * c for c in cost],\n",
    "                \"Tons\": [coeff * t for t in tons],\n",
    "                \"Quantity\": [coeff * q for q in qtyoh], \n",
    "                \"Arrival_Date\": arrival_dates,\n",
    "            }\n",
    "        )\n",
    "        # shipping is chosen to be randomly between 2 and 5 days\n",
    "        bkd_df = pd.DataFrame(\n",
    "            {\n",
    "                \"Item\": items, \n",
    "                \"Ship_Date\": [sd + timedelta(days=random.choice([2,3,4,5])) for sd in arrival_dates],\n",
    "                \"Qty_Remain\": [(1-coeff) * q for q in qtyoh],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return sales_df, hnd_df, ord_df, bkd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, let's set the parameters to generate sales data over 5 years (`num_days`) backwards from today. We'll include 20 items, with each item being sold at 5 locations. Each item belongs to a item class randomly selected from 3 classes (this will be a static covariate when we get to the modeling section). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_days = 365 * 1\n",
    "items = [f\"Item_{idx}\" for idx in range(20)]\n",
    "locations = [f\"Location_{idx}\" for idx in range(5)]\n",
    "item_to_class = {\n",
    "    item: random.choice([\"Item_Class_A\", \"Item_Class_B\", \"Item_Class_C\"])\n",
    "    for item in items\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we generate the data. For this example, we'll generate sinusoidal data (which also incorporates noise). Note that the `min_sales_per_day` argument is negative, meaning that the net sales for the day could be items returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = SalesDataGenerator(\n",
    "    start_date=datetime.today().date() - timedelta(days=num_days),\n",
    "    num_days=num_days,\n",
    "    item_to_location={item: locations for item in items},\n",
    "    item_to_class=item_to_class,\n",
    "    max_sales_per_day=1000,\n",
    "    min_sales_per_day=-100,\n",
    ")\n",
    "sales_data, hnd_data, ord_data, bkd_data = generator.synthesize(data_model=SalesDataModel.SINUSOID)\n",
    "ord_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the dataset defined, we next need to preprocess it compatible with the model training object. To do this, we create a list of dictionaries with specific keys. Note that we are scaling the data in this preprocessing step to be compatable with the statistical structure of the model we define later. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the above datasets into new database inside SQL database: we need to make the tables smaller because we create a huge dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to persist item 0       Item_0\n",
      "1       Item_0\n",
      "2       Item_0\n",
      "3       Item_0\n",
      "4       Item_0\n",
      "         ...  \n",
      "2695    Item_4\n",
      "2696    Item_4\n",
      "2697    Item_4\n",
      "2698    Item_4\n",
      "2699    Item_4\n",
      "Name: Item, Length: 2700, dtype: object to the DB\n",
      "data        Unnamed: 0        Date    Item    Location  Sales    Item_Class\n",
      "0              0  2022-05-25  Item_0  Location_0    936  Item_Class_B\n",
      "1              1  2022-05-26  Item_0  Location_0    942  Item_Class_B\n",
      "2              2  2022-05-27  Item_0  Location_0    893  Item_Class_B\n",
      "3              3  2022-05-28  Item_0  Location_0    931  Item_Class_B\n",
      "4              4  2022-05-29  Item_0  Location_0    901  Item_Class_B\n",
      "...          ...         ...     ...         ...    ...           ...\n",
      "2695        2695  2022-11-16  Item_4  Location_2    888  Item_Class_A\n",
      "2696        2696  2022-11-17  Item_4  Location_2    962  Item_Class_A\n",
      "2697        2697  2022-11-18  Item_4  Location_2    988  Item_Class_A\n",
      "2698        2698  2022-11-19  Item_4  Location_2    932  Item_Class_A\n",
      "2699        2699  2022-11-20  Item_4  Location_2    983  Item_Class_A\n",
      "\n",
      "[2700 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "num_rows = 1000\n",
    "col_names = list(sales_data.columns)\n",
    "sales_data_small = sales_data.loc[0:num_rows,col_names]\n",
    "sales_data_small.shape\n",
    "\n",
    "def get_engine():\n",
    "    server = 'tcp:sql-sa-htt2.database.windows.net' \n",
    "    database = 'supplychain'\n",
    "    username = 'sasqladmin' \n",
    "    password = 'SA-G10rg10-!$!$' \n",
    "\n",
    "    quoted = urllib.parse.quote_plus('DRIVER={ODBC Driver 17 for SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "    engine = create_engine('mssql+pyodbc:///?odbc_connect={}'.format(quoted))\n",
    "\n",
    "    return engine\n",
    "engine=get_engine()\n",
    "\n",
    "\n",
    "try:\n",
    "    sales_data_small.astype(str).to_sql('sc_sales_data', if_exists='append', schema='dbo', con = engine, index=False)\n",
    "    print(\"Persisted Sales Data into the DB\")\n",
    "except:\n",
    "    print(\"failed to persist item {} to the DB\".format(sales_data['Item']))\n",
    "    print(\"data \", sales_data_small)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepopulate the Parameters Table Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n",
      "Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n",
      "Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n",
      "Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n",
      "Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n",
      "Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##Populate the params table DO THIS ONLY ONCE\n",
    "\n",
    "def get_engine():\n",
    "    server = 'tcp:sql-sa-htt2.database.windows.net' \n",
    "    database = 'supplychain'\n",
    "    username = 'sasqladmin' \n",
    "    password = 'SA-G10rg10-!$!$' \n",
    "\n",
    "    quoted = urllib.parse.quote_plus('DRIVER={ODBC Driver 17 for SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "    engine = create_engine('mssql+pyodbc:///?odbc_connect={}'.format(quoted))\n",
    "\n",
    "    return engine\n",
    "\n",
    "# Quick overview of this function, it picks up the new datasets and puts in the format that you can generate the new demand forecast and\n",
    "# the input format for the optimization function\n",
    "def create_ensemble_test_ds(sales_data):\n",
    "    items = [f\"Item_{idx}\" for idx in range(5)]\n",
    "    item_to_class = {\n",
    "        item: random.choice([\"Item_Class_A\", \"Item_Class_B\", \"Item_Class_C\"])\n",
    "        for item in items\n",
    "    } \n",
    "    #print(item_to_class)\n",
    "\n",
    "    ## create variables\n",
    "    start = sales_data.Date.min()\n",
    "    end = sales_data.Date.max()\n",
    "    dates = list(pd.date_range(start, end))\n",
    "\n",
    "    # create ensemble\n",
    "    ensemble = []\n",
    "\n",
    "    for item in set(sales_data.Item): \n",
    "        for location in set(sales_data.Location):\n",
    "            sales = sales_data[(sales_data.Item == item) & (sales_data.Location == location)].Sales.values\n",
    "            if len(sales): \n",
    "                scale = max(abs(sales))\n",
    "                ensemble.append(\n",
    "                    {\n",
    "                        \"class\": item_to_class[item],\n",
    "                        \"item\": item,\n",
    "                        \"sales\": sales,\n",
    "                        \"start\": start,\n",
    "                        \"end\": end,\n",
    "                        \"total\": sum(sales),\n",
    "                        \"scale\": scale,\n",
    "                        \"location\": location,\n",
    "                        \"sales_scaled\": sales / scale,\n",
    "                    }\n",
    "                )\n",
    "    ensemble = sorted(ensemble, key=lambda k: k[\"total\"], reverse=True)\n",
    "    # create test ds \n",
    "    static_cats = [(e[\"class\"].strip(), e[\"item\"].strip(), e[\"location\"].strip()) for e in ensemble]\n",
    "    test_target_values = np.array([np.array(e[\"sales_scaled\"]) for e in ensemble])\n",
    "    item_to_index = {item: idx for idx, item in enumerate(set([sc[0] for sc in static_cats]))}\n",
    "    item_class_to_index = {item: idx for idx, item in enumerate(set([sc[1] for sc in static_cats]))}\n",
    "    location_to_index = {loc: idx for idx, loc in enumerate(set([sc[2] for sc in static_cats]))}\n",
    "\n",
    "    test_ds = ListDataset([\n",
    "        {\n",
    "            FieldName.TARGET: target,\n",
    "            FieldName.START: start,\n",
    "            FieldName.FEAT_STATIC_CAT: [\n",
    "                item_to_index[sc_item], \n",
    "                item_class_to_index[sc_item_class], \n",
    "                location_to_index[sc_location]\n",
    "            ],\n",
    "        }\n",
    "        for target, (sc_item, sc_item_class, sc_location) in zip(test_target_values, static_cats)\n",
    "    ], freq=\"D\")\n",
    "\n",
    "    return ensemble, test_ds \n",
    "\n",
    "def generate_forecasts(dataset, predictor, num_samples):\n",
    "        \n",
    "        forecast_it, _ = make_evaluation_predictions(dataset=dataset, predictor=predictor, num_samples=num_samples)\n",
    "        forecasts = [f for f in forecast_it]\n",
    "\n",
    "        return forecasts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset = Dataset.get_by_name(workspace, name='training_sales_data_2', version='latest')\n",
    "sales_data = dataset.to_pandas_dataframe() \n",
    "ensemble,test_ds = create_ensemble_test_ds(sales_data)\n",
    "df_params = pd.DataFrame(ensemble)\n",
    "\n",
    "df_params.drop(['sales','start','end','total','scale','sales_scaled'],axis=1,inplace=True)\n",
    "\n",
    "df_params['Inventory_Capacity']= \" \"\n",
    "df_params['Max_Quantity']=\" \"\n",
    "df_params['Holding_Cost']=\" \"\n",
    "df_params['Order_Cost']=\" \"\n",
    "df_params['Lead_Time']=\" \"\n",
    "df_params['Backlog_Cost']=\" \"\n",
    "df_params['Max_Backlogged']=\" \"\n",
    "df_params['Initial_Inventory']=\" \"\n",
    "\n",
    "\n",
    "                \n",
    "invCap = 1000\n",
    "maxQ =  1000\n",
    "orderCost = 500\n",
    "holdCost =  2 \n",
    "leadTime =  10 \n",
    "backLogCost =  10 \n",
    "maxBackLogged = 1000\n",
    "leadTime = 10\n",
    "initInv = 500\n",
    "\n",
    "for i in range(len(df_params)):\n",
    "\n",
    "    npar = random.randint(i, 100)\n",
    "    \n",
    "    df_params.iloc[i, 3] = invCap + npar\n",
    "    df_params.iloc[i, 4] = maxQ + npar\n",
    "    df_params.iloc[i, 5] = holdCost + npar\n",
    "    df_params.iloc[i, 6] = orderCost + npar\n",
    "    df_params.iloc[i, 7] = leadTime + npar\n",
    "    df_params.iloc[i, 8] = backLogCost + npar\n",
    "    df_params.iloc[i, 9] = maxBackLogged + npar\n",
    "    df_params.iloc[i, 10] = initInv + npar\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>item</th>\n",
       "      <th>location</th>\n",
       "      <th>Inventory_Capacity</th>\n",
       "      <th>Max_Quantity</th>\n",
       "      <th>Holding_Cost</th>\n",
       "      <th>Order_Cost</th>\n",
       "      <th>Lead_Time</th>\n",
       "      <th>Backlog_Cost</th>\n",
       "      <th>Max_Backlogged</th>\n",
       "      <th>Initial_Inventory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Item_Class_B</td>\n",
       "      <td>Item_0</td>\n",
       "      <td>Location_0</td>\n",
       "      <td>1071</td>\n",
       "      <td>1071</td>\n",
       "      <td>73</td>\n",
       "      <td>571</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>1071</td>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Item_Class_B</td>\n",
       "      <td>Item_0</td>\n",
       "      <td>Location_1</td>\n",
       "      <td>1057</td>\n",
       "      <td>1057</td>\n",
       "      <td>59</td>\n",
       "      <td>557</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>1057</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Item_Class_B</td>\n",
       "      <td>Item_0</td>\n",
       "      <td>Location_2</td>\n",
       "      <td>1100</td>\n",
       "      <td>1100</td>\n",
       "      <td>102</td>\n",
       "      <td>600</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>1100</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Item_Class_B</td>\n",
       "      <td>Item_1</td>\n",
       "      <td>Location_0</td>\n",
       "      <td>1020</td>\n",
       "      <td>1020</td>\n",
       "      <td>22</td>\n",
       "      <td>520</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>1020</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Item_Class_B</td>\n",
       "      <td>Item_1</td>\n",
       "      <td>Location_1</td>\n",
       "      <td>1033</td>\n",
       "      <td>1033</td>\n",
       "      <td>35</td>\n",
       "      <td>533</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>1033</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Item_Class_B</td>\n",
       "      <td>Item_1</td>\n",
       "      <td>Location_2</td>\n",
       "      <td>1061</td>\n",
       "      <td>1061</td>\n",
       "      <td>63</td>\n",
       "      <td>561</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>1061</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Item_Class_B</td>\n",
       "      <td>Item_2</td>\n",
       "      <td>Location_0</td>\n",
       "      <td>1030</td>\n",
       "      <td>1030</td>\n",
       "      <td>32</td>\n",
       "      <td>530</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>1030</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Item_Class_B</td>\n",
       "      <td>Item_2</td>\n",
       "      <td>Location_1</td>\n",
       "      <td>1076</td>\n",
       "      <td>1076</td>\n",
       "      <td>78</td>\n",
       "      <td>576</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>1076</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Item_Class_B</td>\n",
       "      <td>Item_2</td>\n",
       "      <td>Location_2</td>\n",
       "      <td>1099</td>\n",
       "      <td>1099</td>\n",
       "      <td>101</td>\n",
       "      <td>599</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>1099</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Item_Class_C</td>\n",
       "      <td>Item_3</td>\n",
       "      <td>Location_0</td>\n",
       "      <td>1016</td>\n",
       "      <td>1016</td>\n",
       "      <td>18</td>\n",
       "      <td>516</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>1016</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Item_Class_C</td>\n",
       "      <td>Item_3</td>\n",
       "      <td>Location_1</td>\n",
       "      <td>1065</td>\n",
       "      <td>1065</td>\n",
       "      <td>67</td>\n",
       "      <td>565</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>1065</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Item_Class_C</td>\n",
       "      <td>Item_3</td>\n",
       "      <td>Location_2</td>\n",
       "      <td>1042</td>\n",
       "      <td>1042</td>\n",
       "      <td>44</td>\n",
       "      <td>542</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>1042</td>\n",
       "      <td>542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Item_Class_C</td>\n",
       "      <td>Item_4</td>\n",
       "      <td>Location_0</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>26</td>\n",
       "      <td>524</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>1024</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Item_Class_C</td>\n",
       "      <td>Item_4</td>\n",
       "      <td>Location_1</td>\n",
       "      <td>1029</td>\n",
       "      <td>1029</td>\n",
       "      <td>31</td>\n",
       "      <td>529</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>1029</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Item_Class_C</td>\n",
       "      <td>Item_4</td>\n",
       "      <td>Location_2</td>\n",
       "      <td>1082</td>\n",
       "      <td>1082</td>\n",
       "      <td>84</td>\n",
       "      <td>582</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>1082</td>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           class    item    location Inventory_Capacity Max_Quantity  \\\n",
       "12  Item_Class_B  Item_0  Location_0               1071         1071   \n",
       "0   Item_Class_B  Item_0  Location_1               1057         1057   \n",
       "8   Item_Class_B  Item_0  Location_2               1100         1100   \n",
       "3   Item_Class_B  Item_1  Location_0               1020         1020   \n",
       "2   Item_Class_B  Item_1  Location_1               1033         1033   \n",
       "5   Item_Class_B  Item_1  Location_2               1061         1061   \n",
       "6   Item_Class_B  Item_2  Location_0               1030         1030   \n",
       "1   Item_Class_B  Item_2  Location_1               1076         1076   \n",
       "9   Item_Class_B  Item_2  Location_2               1099         1099   \n",
       "13  Item_Class_C  Item_3  Location_0               1016         1016   \n",
       "11  Item_Class_C  Item_3  Location_1               1065         1065   \n",
       "10  Item_Class_C  Item_3  Location_2               1042         1042   \n",
       "7   Item_Class_C  Item_4  Location_0               1024         1024   \n",
       "4   Item_Class_C  Item_4  Location_1               1029         1029   \n",
       "14  Item_Class_C  Item_4  Location_2               1082         1082   \n",
       "\n",
       "   Holding_Cost Order_Cost Lead_Time Backlog_Cost Max_Backlogged  \\\n",
       "12           73        571        81           81           1071   \n",
       "0            59        557        67           67           1057   \n",
       "8           102        600       110          110           1100   \n",
       "3            22        520        30           30           1020   \n",
       "2            35        533        43           43           1033   \n",
       "5            63        561        71           71           1061   \n",
       "6            32        530        40           40           1030   \n",
       "1            78        576        86           86           1076   \n",
       "9           101        599       109          109           1099   \n",
       "13           18        516        26           26           1016   \n",
       "11           67        565        75           75           1065   \n",
       "10           44        542        52           52           1042   \n",
       "7            26        524        34           34           1024   \n",
       "4            31        529        39           39           1029   \n",
       "14           84        582        92           92           1082   \n",
       "\n",
       "   Initial_Inventory  \n",
       "12               571  \n",
       "0                557  \n",
       "8                600  \n",
       "3                520  \n",
       "2                533  \n",
       "5                561  \n",
       "6                530  \n",
       "1                576  \n",
       "9                599  \n",
       "13               516  \n",
       "11               565  \n",
       "10               542  \n",
       "7                524  \n",
       "4                529  \n",
       "14               582  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_params.sort_values(by=['class','item','location']).head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisted Parameters Table successfully to the DB\n"
     ]
    }
   ],
   "source": [
    "engine = get_engine()\n",
    "\n",
    "try:\n",
    "    df_params.astype(str).to_sql('sc_params_table', if_exists='append', schema='dbo', con = engine,index_label=None)\n",
    "    print(\"Persisted Parameters Table successfully to the DB\")\n",
    "except pyodbc.Error as err: \n",
    "    raise err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "local_env"
  },
  "kernelspec": {
   "display_name": "supplychain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "5d26f6d4e782b599352b2ffa2320499d09ac11e1fadee5b63d00d8b9c096a0ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
